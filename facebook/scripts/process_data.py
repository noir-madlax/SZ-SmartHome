#!/usr/bin/env python3
"""
Facebookç¾¤ç»„æ•°æ®å¤„ç†è„šæœ¬
å¤„ç†å’Œåˆ†æä¸‹è½½çš„Smart Homeç¾¤ç»„æ•°æ®
"""

import os
import sys
import argparse
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.data_processor import DataProcessor
from config.settings import RAW_DATA_DIR, PROCESSED_DATA_DIR

def process_file(filepath: str, output_format: str = 'json'):
    """å¤„ç†æŒ‡å®šæ–‡ä»¶"""
    processor = DataProcessor()
    
    try:
        print(f"åŠ è½½æ•°æ®æ–‡ä»¶: {filepath}")
        data = processor.load_data(filepath)
        print(f"åŸå§‹æ•°æ®è®°å½•æ•°: {len(data)}")
        
        print("\nå¤„ç†å¸–å­æ•°æ®...")
        df = processor.process_posts(data)
        
        if df.empty:
            print("âŒ æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®")
            return None
        
        print(f"å¤„ç†åè®°å½•æ•°: {len(df)}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = processor.get_summary_stats(df)
        print("\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  æ€»å¸–å­æ•°: {stats['total_posts']}")
        print(f"  ç”¨æˆ·æ•°: {stats['unique_users']}")
        print(f"  æ—¶é—´èŒƒå›´: {stats['date_range']['start']} åˆ° {stats['date_range']['end']}")
        print(f"  æ€»ç‚¹èµæ•°: {stats['engagement_stats']['total_likes']}")
        print(f"  æ€»è¯„è®ºæ•°: {stats['engagement_stats']['total_comments']}")
        print(f"  æ€»åˆ†äº«æ•°: {stats['engagement_stats']['total_shares']}")
        print(f"  å¹³å‡äº’åŠ¨åˆ†æ•°: {stats['engagement_stats']['avg_engagement']:.2f}")
        print(f"  åŒ…å«å›¾ç‰‡çš„å¸–å­: {stats['content_stats']['posts_with_images']}")
        print(f"  åŒ…å«è¯é¢˜æ ‡ç­¾çš„å¸–å­: {stats['content_stats']['posts_with_hashtags']}")
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        print(f"\nä¿å­˜å¤„ç†åçš„æ•°æ® (æ ¼å¼: {output_format})...")
        output_filepath = processor.save_processed_data(df, format=output_format)
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_filename = f"stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        stats_filepath = os.path.join(PROCESSED_DATA_DIR, stats_filename)
        with open(stats_filepath, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2, default=str)
        print(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_filepath}")
        
        print(f"\nâœ… æ•°æ®å¤„ç†å®Œæˆ!")
        return output_filepath
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        return None

def list_raw_files():
    """åˆ—å‡ºåŸå§‹æ•°æ®æ–‡ä»¶"""
    if not os.path.exists(RAW_DATA_DIR):
        print("âŒ åŸå§‹æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return []
    
    files = [f for f in os.listdir(RAW_DATA_DIR) if f.endswith('.json')]
    
    if not files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŸå§‹æ•°æ®æ–‡ä»¶")
        return []
    
    print("åŸå§‹æ•°æ®æ–‡ä»¶:")
    print("-" * 60)
    for i, filename in enumerate(files, 1):
        filepath = os.path.join(RAW_DATA_DIR, filename)
        size = os.path.getsize(filepath)
        mtime = datetime.fromtimestamp(os.path.getmtime(filepath))
        print(f"{i:2d}. {filename:<30} ({size:,} bytes, {mtime.strftime('%Y-%m-%d %H:%M')})")
    
    return files

def process_latest_file(output_format: str = 'json'):
    """å¤„ç†æœ€æ–°çš„åŸå§‹æ•°æ®æ–‡ä»¶"""
    files = list_raw_files()
    if not files:
        return None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°æ–‡ä»¶
    files_with_time = []
    for filename in files:
        filepath = os.path.join(RAW_DATA_DIR, filename)
        mtime = os.path.getmtime(filepath)
        files_with_time.append((filename, mtime))
    
    files_with_time.sort(key=lambda x: x[1], reverse=True)
    latest_file = files_with_time[0][0]
    
    print(f"\nå¤„ç†æœ€æ–°æ–‡ä»¶: {latest_file}")
    latest_filepath = os.path.join(RAW_DATA_DIR, latest_file)
    
    return process_file(latest_filepath, output_format)

def analyze_trends(filepath: str):
    """åˆ†æè¶‹åŠ¿æ•°æ®"""
    processor = DataProcessor()
    
    try:
        data = processor.load_data(filepath)
        df = processor.process_posts(data)
        
        if df.empty:
            print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return
        
        print("\nğŸ“ˆ è¶‹åŠ¿åˆ†æ:")
        
        # æŒ‰æ—¥æœŸåˆ†ç»„åˆ†æ
        if 'post_time' in df.columns and not df['post_time'].isnull().all():
            df['date'] = df['post_time'].dt.date
            daily_stats = df.groupby('date').agg({
                'post_id': 'count',
                'likes_count': 'sum',
                'comments_count': 'sum',
                'engagement_score': 'mean'
            }).rename(columns={'post_id': 'posts_count'})
            
            print("\næ¯æ—¥ç»Ÿè®¡ (æœ€è¿‘10å¤©):")
            print("-" * 70)
            print(f"{'æ—¥æœŸ':<12} {'å¸–å­æ•°':<8} {'ç‚¹èµæ•°':<8} {'è¯„è®ºæ•°':<8} {'å¹³å‡äº’åŠ¨':<10}")
            print("-" * 70)
            
            for date, row in daily_stats.tail(10).iterrows():
                print(f"{date} {int(row['posts_count']):>6} {int(row['likes_count']):>7} {int(row['comments_count']):>7} {row['engagement_score']:>9.1f}")
        
        # ç”¨æˆ·æ´»è·ƒåº¦åˆ†æ
        user_stats = df.groupby('user_name').agg({
            'post_id': 'count',
            'likes_count': 'sum',
            'engagement_score': 'mean'
        }).rename(columns={'post_id': 'posts_count'}).sort_values('posts_count', ascending=False)
        
        print(f"\næœ€æ´»è·ƒç”¨æˆ· (Top 10):")
        print("-" * 60)
        print(f"{'ç”¨æˆ·å':<20} {'å¸–å­æ•°':<8} {'æ€»ç‚¹èµ':<8} {'å¹³å‡äº’åŠ¨':<10}")
        print("-" * 60)
        
        for user, row in user_stats.head(10).iterrows():
            print(f"{user[:18]:<20} {int(row['posts_count']):>6} {int(row['likes_count']):>7} {row['engagement_score']:>9.1f}")
        
        # è¯é¢˜æ ‡ç­¾åˆ†æ
        if 'hashtags' in df.columns:
            all_hashtags = []
            for hashtags in df['hashtags']:
                if isinstance(hashtags, list):
                    all_hashtags.extend(hashtags)
            
            if all_hashtags:
                from collections import Counter
                hashtag_counts = Counter(all_hashtags)
                
                print(f"\nçƒ­é—¨è¯é¢˜æ ‡ç­¾ (Top 10):")
                print("-" * 30)
                for hashtag, count in hashtag_counts.most_common(10):
                    print(f"{hashtag:<20} {count:>6}")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {str(e)}")

def main():
    parser = argparse.ArgumentParser(description='Facebookç¾¤ç»„æ•°æ®å¤„ç†å·¥å…·')
    parser.add_argument('--file', '-f', help='æŒ‡å®šè¦å¤„ç†çš„åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--latest', '-l', action='store_true', help='å¤„ç†æœ€æ–°çš„åŸå§‹æ•°æ®æ–‡ä»¶')
    parser.add_argument('--list', '-ls', action='store_true', help='åˆ—å‡ºåŸå§‹æ•°æ®æ–‡ä»¶')
    parser.add_argument('--format', '-fmt', choices=['json', 'csv', 'xlsx'], default='json', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--analyze', '-a', help='åˆ†ææŒ‡å®šæ–‡ä»¶çš„è¶‹åŠ¿æ•°æ®')
    
    args = parser.parse_args()
    
    if args.list:
        list_raw_files()
    elif args.file:
        if os.path.exists(args.file):
            process_file(args.file, args.format)
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.file}")
    elif args.latest:
        process_latest_file(args.format)
    elif args.analyze:
        if os.path.exists(args.analyze):
            analyze_trends(args.analyze)
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.analyze}")
    else:
        print("è¯·æŒ‡å®šæ“ä½œé€‰é¡¹:")
        print("  --file <path>     å¤„ç†æŒ‡å®šçš„åŸå§‹æ•°æ®æ–‡ä»¶")
        print("  --latest          å¤„ç†æœ€æ–°çš„åŸå§‹æ•°æ®æ–‡ä»¶")
        print("  --list            åˆ—å‡ºåŸå§‹æ•°æ®æ–‡ä»¶")
        print("  --format <fmt>    æŒ‡å®šè¾“å‡ºæ ¼å¼ (json/csv/xlsx)")
        print("  --analyze <path>  åˆ†ææŒ‡å®šæ–‡ä»¶çš„è¶‹åŠ¿æ•°æ®")
        print("\nç¤ºä¾‹:")
        print("  python process_data.py --latest --format csv")
        print("  python process_data.py --file data/raw/facebook_posts_xxx.json")
        print("  python process_data.py --analyze data/raw/facebook_posts_xxx.json")

if __name__ == "__main__":
    main() 